{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE not available. Using alternative oversampling method.\n",
      "XGBoost not available. Install with: pip install xgboost\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pickle\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Try to import SMOTE, if it fails, create alternative class\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "except ImportError:\n",
    "    print(\"SMOTE not available. Using alternative oversampling method.\")\n",
    "    from sklearn.utils import resample\n",
    "    \n",
    "    class SMOTE:\n",
    "        def __init__(self, random_state=42):\n",
    "            self.random_state = random_state\n",
    "        \n",
    "        def fit_resample(self, X, y):\n",
    "            df = pd.concat([pd.DataFrame(X), pd.Series(y, name='target')], axis=1)\n",
    "            classes = df['target'].value_counts()\n",
    "            max_count = classes.max()\n",
    "            \n",
    "            oversampled = []\n",
    "            for class_label in classes.index:\n",
    "                class_df = df[df['target'] == class_label]\n",
    "                if len(class_df) < max_count:\n",
    "                    oversampled_class = resample(class_df, replace=True, n_samples=max_count, random_state=self.random_state)\n",
    "                    oversampled.append(oversampled_class)\n",
    "                else:\n",
    "                    oversampled.append(class_df)\n",
    "            \n",
    "            result_df = pd.concat(oversampled).sample(frac=1, random_state=self.random_state)\n",
    "            return result_df.drop('target', axis=1).values, result_df['target'].values\n",
    "\n",
    "# Try to import XGBoost\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "except ImportError:\n",
    "    print(\"XGBoost not available. Install with: pip install xgboost\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Your machine learning code can start here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\ragul\\OneDrive\\Desktop\\CareerPath_Recommender-main\\Jupiter file & dataset\\student-scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop unnecessary columns\n",
    "df.drop(columns=['id', 'first_name', 'last_name', 'email'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate total and average scores\n",
    "df[\"total_score\"] = (\n",
    "    df[\"math_score\"] + df[\"history_score\"] + df[\"physics_score\"] +\n",
    "    df[\"chemistry_score\"] + df[\"biology_score\"] + df[\"english_score\"] + df[\"geography_score\"]\n",
    ")\n",
    "df[\"average_score\"] = df[\"total_score\"] / 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map categorical variables\n",
    "gender_map = {'male': 0, 'female': 1}\n",
    "part_time_job_map = {False: 0, True: 1}\n",
    "extracurricular_activities_map = {False: 0, True: 1}\n",
    "career_aspiration_map = {\n",
    "    'Lawyer': 0, 'Doctor': 1, 'Government Officer': 2, 'Artist': 3, 'Unknown': 4,\n",
    "    'Software Engineer': 5, 'Teacher': 6, 'Business Owner': 7, 'Scientist': 8,\n",
    "    'Banker': 9, 'Writer': 10, 'Accountant': 11, 'Designer': 12,\n",
    "    'Construction Engineer': 13, 'Game Developer': 14, 'Stock Investor': 15,\n",
    "    'Real Estate Developer': 16\n",
    "}\n",
    "\n",
    "df['gender'] = df['gender'].map(gender_map)\n",
    "df['part_time_job'] = df['part_time_job'].map(part_time_job_map)\n",
    "df['extracurricular_activities'] = df['extracurricular_activities'].map(extracurricular_activities_map)\n",
    "df['career_aspiration'] = df['career_aspiration'].map(career_aspiration_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('career_aspiration', axis=1)\n",
    "y = df['career_aspiration']\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost not available. Proceeding without it.\n",
      "==================================================\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.41456582633053224\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.40      0.43        75\n",
      "           1       0.40      0.63      0.49        57\n",
      "           2       0.41      0.26      0.32        70\n",
      "           3       0.49      0.57      0.53        56\n",
      "           4       0.25      0.15      0.19        67\n",
      "           5       0.28      0.18      0.21        74\n",
      "           6       0.49      0.66      0.57        62\n",
      "           7       0.76      0.73      0.75        71\n",
      "           8       0.51      0.56      0.53        57\n",
      "           9       0.18      0.09      0.12        68\n",
      "          10       0.44      0.52      0.47        64\n",
      "          11       0.26      0.40      0.32        48\n",
      "          12       0.18      0.13      0.15        68\n",
      "          13       0.36      0.58      0.45        60\n",
      "          14       0.57      0.89      0.70        61\n",
      "          15       0.25      0.13      0.17        62\n",
      "          16       0.30      0.31      0.30        51\n",
      "\n",
      "    accuracy                           0.41      1071\n",
      "   macro avg       0.39      0.42      0.39      1071\n",
      "weighted avg       0.39      0.41      0.39      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[30  6  0  0  1 10  0  0  1  4 14  2  2  5  0  0  0]\n",
      " [ 3 36  0  0  0  3  0  0  7  0  2  0  3  3  0  0  0]\n",
      " [ 0  0 18  7  8  0 11  0  0  0  1  0  5  4  4  1 11]\n",
      " [ 0  0  2 32  0  0  2  6  0  0  0  0  0  0  7  0  7]\n",
      " [ 3  7  5  2 10  3  3  1  3  4  1 11  3  4  2  2  3]\n",
      " [ 6  3  0  0  2 13  1  0  3  8  1 10  3 16  0  8  0]\n",
      " [ 0  0  3  0  0  2 41  0  0  4  0  2  8  0  0  0  2]\n",
      " [ 0  0  1  6  0  0  0 52  0  0  0  0  0  0  6  0  6]\n",
      " [ 0 16  0  0  0  0  0  0 32  0  5  0  0  4  0  0  0]\n",
      " [ 5  0  4  0  3  4  6  0  8  6  6  6  6  7  0  6  1]\n",
      " [ 9  6  0  0  0  0  7  0  1  0 33  0  4  4  0  0  0]\n",
      " [ 3  2  0  0  3  5  2  0  2  4  1 19  3  3  0  1  0]\n",
      " [ 0  4  1  2 11  1  7  1  2  1  5  0  9  3 12  6  3]\n",
      " [ 3  6  0  0  1  2  0  0  0  2  4  7  0 35  0  0  0]\n",
      " [ 0  0  0  6  0  0  0  0  0  0  0  0  0  0 54  0  1]\n",
      " [ 4  3  4  0  1  4  0  0  4  1  2 15  3  8  1  8  4]\n",
      " [ 0  0  6 10  0  0  3  8  0  0  0  0  0  0  8  0 16]]\n",
      "==================================================\n",
      "Model: Support Vector Classifier\n",
      "Accuracy: 0.6685340802987861\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.63      0.57        75\n",
      "           1       0.66      0.82      0.73        57\n",
      "           2       0.72      0.79      0.75        70\n",
      "           3       0.81      0.84      0.82        56\n",
      "           4       0.72      0.31      0.44        67\n",
      "           5       0.41      0.28      0.34        74\n",
      "           6       0.73      0.87      0.79        62\n",
      "           7       0.85      0.75      0.80        71\n",
      "           8       0.65      0.93      0.76        57\n",
      "           9       0.51      0.40      0.45        68\n",
      "          10       0.86      0.80      0.83        64\n",
      "          11       0.64      0.52      0.57        48\n",
      "          12       0.83      0.57      0.68        68\n",
      "          13       0.54      0.82      0.65        60\n",
      "          14       0.73      0.92      0.81        61\n",
      "          15       0.66      0.56      0.61        62\n",
      "          16       0.59      0.71      0.64        51\n",
      "\n",
      "    accuracy                           0.67      1071\n",
      "   macro avg       0.67      0.68      0.66      1071\n",
      "weighted avg       0.67      0.67      0.66      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[47  6  0  0  2  2  0  0  1  8  3  1  0  5  0  0  0]\n",
      " [ 1 47  0  0  0  0  0  0  5  0  0  0  2  1  0  1  0]\n",
      " [ 0  0 55  0  0  0  6  0  0  0  0  0  0  4  3  0  2]\n",
      " [ 0  0  1 47  0  0  0  0  0  0  0  0  0  0  3  0  5]\n",
      " [ 3  6  8  0 21  7  0  3  2  3  2  3  1  3  3  1  1]\n",
      " [ 8  3  0  0  0 21  1  0  2  9  0  6  0 16  0  8  0]\n",
      " [ 0  0  0  1  0  3 54  0  0  2  0  0  2  0  0  0  0]\n",
      " [ 0  0  2  4  0  0  0 53  0  0  0  0  0  0  3  1  8]\n",
      " [ 3  1  0  0  0  0  0  0 53  0  0  0  0  0  0  0  0]\n",
      " [ 7  2  3  0  0  6  5  0  4 27  0  1  1  5  0  6  1]\n",
      " [ 6  0  0  0  0  0  0  0  7  0 51  0  0  0  0  0  0]\n",
      " [ 4  2  1  0  3  4  1  0  2  3  0 25  0  3  0  0  0]\n",
      " [ 3  0  0  0  2  1  5  0  5  0  0  0 39  1  6  0  6]\n",
      " [ 1  2  1  0  0  3  0  0  1  0  2  0  0 49  0  1  0]\n",
      " [ 0  0  0  3  0  0  0  0  0  0  0  0  0  0 56  0  2]\n",
      " [ 6  2  3  0  1  4  0  0  0  1  1  3  2  3  1 35  0]\n",
      " [ 0  0  2  3  0  0  2  6  0  0  0  0  0  0  2  0 36]]\n",
      "==================================================\n",
      "Model: Random Forest Classifier\n",
      "Accuracy: 0.9243697478991597\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87        75\n",
      "           1       0.89      1.00      0.94        57\n",
      "           2       0.97      1.00      0.99        70\n",
      "           3       0.97      1.00      0.98        56\n",
      "           4       0.94      0.87      0.90        67\n",
      "           5       0.73      0.50      0.59        74\n",
      "           6       0.95      1.00      0.98        62\n",
      "           7       0.94      0.93      0.94        71\n",
      "           8       0.98      1.00      0.99        57\n",
      "           9       0.88      0.84      0.86        68\n",
      "          10       0.97      1.00      0.98        64\n",
      "          11       0.92      0.92      0.92        48\n",
      "          12       0.97      0.99      0.98        68\n",
      "          13       0.87      1.00      0.93        60\n",
      "          14       0.97      1.00      0.98        61\n",
      "          15       0.92      0.97      0.94        62\n",
      "          16       0.98      0.94      0.96        51\n",
      "\n",
      "    accuracy                           0.92      1071\n",
      "   macro avg       0.92      0.93      0.93      1071\n",
      "weighted avg       0.92      0.92      0.92      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[66  1  0  0  0  4  0  0  0  1  1  0  0  2  0  0  0]\n",
      " [ 0 57  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 70  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 56  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  3  1  0 58  3  0  1  1  0  0  0  0  0  0  0  0]\n",
      " [10  2  1  0  0 37  1  0  0  7  1  3  2  7  0  3  0]\n",
      " [ 0  0  0  0  0  0 62  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  0  0  0 66  0  0  0  0  0  0  2  0  1]\n",
      " [ 0  0  0  0  0  0  0  0 57  0  0  0  0  0  0  0  0]\n",
      " [ 1  1  0  0  3  2  1  0  0 57  0  1  0  0  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 64  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  3  0  0  0  0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0  0 67  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 60  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 61  0  0]\n",
      " [ 0  0  0  0  0  2  0  0  0  0  0  0  0  0  0 60  0]\n",
      " [ 0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0 48]]\n",
      "==================================================\n",
      "Model: K Nearest Neighbors\n",
      "Accuracy: 0.7189542483660131\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.71      0.72        75\n",
      "           1       0.68      0.91      0.78        57\n",
      "           2       0.75      0.90      0.82        70\n",
      "           3       0.76      0.95      0.84        56\n",
      "           4       0.63      0.33      0.43        67\n",
      "           5       0.31      0.12      0.17        74\n",
      "           6       0.73      0.95      0.83        62\n",
      "           7       0.93      0.54      0.68        71\n",
      "           8       0.85      1.00      0.92        57\n",
      "           9       0.52      0.49      0.50        68\n",
      "          10       0.86      1.00      0.93        64\n",
      "          11       0.56      0.52      0.54        48\n",
      "          12       0.70      0.84      0.77        68\n",
      "          13       0.74      0.85      0.79        60\n",
      "          14       0.87      0.89      0.88        61\n",
      "          15       0.67      0.71      0.69        62\n",
      "          16       0.67      0.71      0.69        51\n",
      "\n",
      "    accuracy                           0.72      1071\n",
      "   macro avg       0.70      0.73      0.70      1071\n",
      "weighted avg       0.70      0.72      0.70      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[53  0  0  0  2  1  0  0  0 10  3  2  0  0  0  4  0]\n",
      " [ 1 52  0  0  0  0  0  0  3  0  0  0  0  1  0  0  0]\n",
      " [ 0  0 63  1  0  0  0  0  0  0  1  0  0  0  0  0  5]\n",
      " [ 0  0  0 53  1  0  0  1  0  0  0  0  0  0  1  0  0]\n",
      " [ 2  4  6  3 22  2  3  1  3  3  4  4  3  2  1  3  1]\n",
      " [ 8  8  1  1  1  9  2  0  2 11  0 10  4 10  0  7  0]\n",
      " [ 0  0  0  0  1  2 59  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  6  5  1  1  2 38  0  0  0  0  4  1  0  3  9]\n",
      " [ 0  0  0  0  0  0  0  0 57  0  0  0  0  0  0  0  0]\n",
      " [ 6  5  5  2  1  2  6  0  1 33  0  3  1  0  0  3  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 64  0  0  0  0  0  0]\n",
      " [ 2  0  1  1  2  6  3  0  0  3  1 25  1  2  0  1  0]\n",
      " [ 0  1  0  2  1  4  2  0  0  0  1  0 57  0  0  0  0]\n",
      " [ 0  3  1  0  1  1  0  0  1  1  0  0  0 51  1  0  0]\n",
      " [ 0  0  0  0  0  0  2  0  0  0  0  0  2  0 54  0  3]\n",
      " [ 1  2  0  0  1  1  0  0  0  3  0  0  5  2  3 44  0]\n",
      " [ 0  0  1  2  1  0  2  1  0  0  0  1  4  0  2  1 36]]\n",
      "==================================================\n",
      "Model: Decision Tree Classifier\n",
      "Accuracy: 0.8982259570494865\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84        75\n",
      "           1       0.95      0.98      0.97        57\n",
      "           2       0.96      1.00      0.98        70\n",
      "           3       0.93      1.00      0.97        56\n",
      "           4       0.83      0.82      0.83        67\n",
      "           5       0.67      0.27      0.38        74\n",
      "           6       0.97      1.00      0.98        62\n",
      "           7       0.98      0.80      0.88        71\n",
      "           8       1.00      1.00      1.00        57\n",
      "           9       0.76      0.84      0.80        68\n",
      "          10       0.94      1.00      0.97        64\n",
      "          11       0.83      0.92      0.87        48\n",
      "          12       0.93      0.99      0.96        68\n",
      "          13       0.88      0.97      0.92        60\n",
      "          14       0.98      1.00      0.99        61\n",
      "          15       0.86      1.00      0.93        62\n",
      "          16       0.89      1.00      0.94        51\n",
      "\n",
      "    accuracy                           0.90      1071\n",
      "   macro avg       0.89      0.91      0.89      1071\n",
      "weighted avg       0.89      0.90      0.89      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[65  0  0  0  1  1  0  0  0  1  0  3  0  2  0  2  0]\n",
      " [ 0 56  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 70  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 56  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4  1  0  0 55  1  0  1  0  2  0  0  1  0  0  2  0]\n",
      " [ 7  2  1  0  6 20  0  0  0 14  3  6  4  6  0  5  0]\n",
      " [ 0  0  0  0  0  0 62  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  4  2  0  0 57  0  0  0  0  0  0  1  0  6]\n",
      " [ 0  0  0  0  0  0  0  0 57  0  0  0  0  0  0  0  0]\n",
      " [ 3  0  1  0  1  2  2  0  0 57  1  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 64  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  3  0  0  0  0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  0 67  0  0  0  0]\n",
      " [ 0  0  0  0  0  2  0  0  0  0  0  0  0 58  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 61  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 62  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 51]]\n",
      "==================================================\n",
      "Model: Gaussian Naive Bayes\n",
      "Accuracy: 0.24556489262371614\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.20      0.27        75\n",
      "           1       0.47      0.44      0.45        57\n",
      "           2       1.00      0.04      0.08        70\n",
      "           3       0.00      0.00      0.00        56\n",
      "           4       0.40      0.09      0.15        67\n",
      "           5       0.36      0.05      0.09        74\n",
      "           6       0.17      1.00      0.30        62\n",
      "           7       0.83      0.69      0.75        71\n",
      "           8       0.48      0.23      0.31        57\n",
      "           9       0.00      0.00      0.00        68\n",
      "          10       0.53      0.14      0.22        64\n",
      "          11       0.40      0.08      0.14        48\n",
      "          12       0.00      0.00      0.00        68\n",
      "          13       0.13      1.00      0.24        60\n",
      "          14       0.00      0.00      0.00        61\n",
      "          15       0.67      0.03      0.06        62\n",
      "          16       0.46      0.22      0.29        51\n",
      "\n",
      "    accuracy                           0.25      1071\n",
      "   macro avg       0.37      0.25      0.20      1071\n",
      "weighted avg       0.38      0.25      0.20      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[15  1  0  0  0  0 14  0  5  0  4  2  0 34  0  0  0]\n",
      " [ 0 25  0  0  0  0  8  0  3  0  0  0  0 21  0  0  0]\n",
      " [ 0  0  3  0  0  0 39  4  0  0  0  0  0 21  0  0  3]\n",
      " [ 0  0  0  0  0  0 36  4  0  0  0  0  0 14  0  0  2]\n",
      " [ 0  4  0  0  6  3 23  1  0  0  0  2  1 25  0  0  2]\n",
      " [ 4  3  0  0  0  4 20  0  0  0  1  0  0 41  0  1  0]\n",
      " [ 0  0  0  0  0  0 62  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  0  0 10 49  0  0  0  0  0  6  1  0  3]\n",
      " [ 0  7  0  0  0  0  0  0 13  0  0  0  2 35  0  0  0]\n",
      " [ 1  1  0  0  1  2 27  0  5  0  0  2  0 29  0  0  0]\n",
      " [ 8  7  0  0  1  0 13  0  0  0  9  0  0 26  0  0  0]\n",
      " [ 2  1  0  0  0  1 19  0  0  0  1  4  0 20  0  0  0]\n",
      " [ 3  4  0  0  5  0 29  0  1  0  2  0  0 21  0  0  3]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 60  0  0  0]\n",
      " [ 0  0  0  0  0  0 24  0  0  0  0  0  0 37  0  0  0]\n",
      " [ 2  0  0  0  2  1 12  0  0  0  0  0  0 43  0  2  0]\n",
      " [ 0  0  0  1  0  0 21  1  0  0  0  0  0 17  0  0 11]]\n",
      "==================================================\n",
      "Model: AdaBoost Classifier\n",
      "Accuracy: 0.12791783380018673\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        75\n",
      "           1       1.00      0.56      0.72        57\n",
      "           2       0.10      0.50      0.17        70\n",
      "           3       0.00      0.00      0.00        56\n",
      "           4       0.00      0.00      0.00        67\n",
      "           5       0.10      0.28      0.15        74\n",
      "           6       0.00      0.00      0.00        62\n",
      "           7       0.00      0.00      0.00        71\n",
      "           8       0.07      0.04      0.05        57\n",
      "           9       0.00      0.00      0.00        68\n",
      "          10       0.00      0.00      0.00        64\n",
      "          11       1.00      0.12      0.22        48\n",
      "          12       0.05      0.09      0.06        68\n",
      "          13       0.10      0.58      0.18        60\n",
      "          14       0.00      0.00      0.00        61\n",
      "          15       0.00      0.00      0.00        62\n",
      "          16       0.00      0.00      0.00        51\n",
      "\n",
      "    accuracy                           0.13      1071\n",
      "   macro avg       0.14      0.13      0.09      1071\n",
      "weighted avg       0.12      0.13      0.09      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 0  0  0  0  0 35  0  0  4  0  0  0  0 36  0  0  0]\n",
      " [ 0 32  0  0  0 11  0  0  0  0  0  0  0 14  0  0  0]\n",
      " [ 0  0 35  0  0  0  0  0  0  0  0  0 17 18  0  0  0]\n",
      " [ 0  0 56  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 14  0  0 13  0  0  5  0  0  0 14 21  0  0  0]\n",
      " [ 0  0  0  0  0 21  0  0  0  0  0  0 12 41  0  0  0]\n",
      " [ 0  0 20  0  0  0  0  0  0  0  0  0 28 14  0  0  0]\n",
      " [ 0  0 71  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 55  0  0  2  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  2  0  0 15  0  0  2  0  0  0 11 38  0  0  0]\n",
      " [ 0  0  0  0  0 18  0  0  8  0  0  0  7 31  0  0  0]\n",
      " [ 0  0  0  0  0  8  0  0  0  0  0  6  7 27  0  0  0]\n",
      " [ 0  0 20  0  0  6  0  0  4  0  0  0  6 32  0  0  0]\n",
      " [ 0  0  1  0  0 10  0  0  0  0  0  0 14 35  0  0  0]\n",
      " [ 0  0 61  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 10  0  0 14  0  0  2  0  0  0  7 29  0  0  0]\n",
      " [ 0  0 50  0  0  0  0  0  0  0  0  0  1  0  0  0  0]]\n",
      "==================================================\n",
      "Model: Gradient Boosting Classifier\n",
      "Accuracy: 0.869281045751634\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84        75\n",
      "           1       0.93      1.00      0.97        57\n",
      "           2       0.96      0.94      0.95        70\n",
      "           3       0.88      1.00      0.93        56\n",
      "           4       0.91      0.61      0.73        67\n",
      "           5       0.59      0.46      0.52        74\n",
      "           6       0.90      0.98      0.94        62\n",
      "           7       0.95      0.87      0.91        71\n",
      "           8       0.90      1.00      0.95        57\n",
      "           9       0.69      0.74      0.71        68\n",
      "          10       0.97      1.00      0.98        64\n",
      "          11       0.78      0.73      0.75        48\n",
      "          12       0.97      0.88      0.92        68\n",
      "          13       0.83      0.95      0.88        60\n",
      "          14       0.92      1.00      0.96        61\n",
      "          15       0.95      0.90      0.93        62\n",
      "          16       0.87      0.92      0.90        51\n",
      "\n",
      "    accuracy                           0.87      1071\n",
      "   macro avg       0.87      0.88      0.87      1071\n",
      "weighted avg       0.87      0.87      0.86      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[67  1  0  0  0  3  0  0  0  3  0  1  0  0  0  0  0]\n",
      " [ 0 57  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 66  3  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 56  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 3  2  2  1 41  5  0  0  1  4  2  0  0  0  3  1  2]\n",
      " [ 7  0  0  0  4 34  1  0  2 10  0  7  0  8  0  1  0]\n",
      " [ 0  0  0  0  0  1 61  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  0  0  0 62  0  0  0  0  0  0  2  0  5]\n",
      " [ 0  0  0  0  0  0  0  0 57  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  3  5  0  2 50  0  2  1  2  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 64  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  5  0  0  1  3  0 35  1  2  0  0  0]\n",
      " [ 0  1  0  2  0  4  1  0  0  0  0  0 60  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0  0  0  1  0  0  0 57  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 61  0  0]\n",
      " [ 3  0  0  0  0  3  0  0  0  0  0  0  0  0  0 56  0]\n",
      " [ 0  0  1  0  0  0  0  3  0  0  0  0  0  0  0  0 47]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(),\n",
    "        \"Support Vector Classifier\": SVC(),\n",
    "        \"Random Forest Classifier\": RandomForestClassifier(),\n",
    "        \"K Nearest Neighbors\": KNeighborsClassifier(),\n",
    "        \"Decision Tree Classifier\": DecisionTreeClassifier(),\n",
    "        \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "        \"AdaBoost Classifier\": AdaBoostClassifier(),\n",
    "        \"Gradient Boosting Classifier\": GradientBoostingClassifier(),\n",
    "        \"XGBoost Classifier\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "    }\n",
    "except ImportError:\n",
    "    print(\"XGBoost not available. Proceeding without it.\")\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(),\n",
    "        \"Support Vector Classifier\": SVC(),\n",
    "        \"Random Forest Classifier\": RandomForestClassifier(),\n",
    "        \"K Nearest Neighbors\": KNeighborsClassifier(),\n",
    "        \"Decision Tree Classifier\": DecisionTreeClassifier(),\n",
    "        \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "        \"AdaBoost Classifier\": AdaBoostClassifier(),\n",
    "        \"Gradient Boosting Classifier\": GradientBoostingClassifier()\n",
    "    }\n",
    "\n",
    "# Train and evaluate models\n",
    "for name, model in models.items():\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Model:\", name)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Random Forest Classifier Evaluation ===\n",
      "Accuracy: 0.9299719887955182\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89        75\n",
      "           1       0.90      1.00      0.95        57\n",
      "           2       0.96      1.00      0.98        70\n",
      "           3       0.97      1.00      0.98        56\n",
      "           4       0.97      0.87      0.91        67\n",
      "           5       0.70      0.50      0.58        74\n",
      "           6       0.95      1.00      0.98        62\n",
      "           7       0.96      0.96      0.96        71\n",
      "           8       0.97      1.00      0.98        57\n",
      "           9       0.84      0.85      0.85        68\n",
      "          10       0.98      1.00      0.99        64\n",
      "          11       0.96      0.94      0.95        48\n",
      "          12       0.99      0.99      0.99        68\n",
      "          13       0.90      1.00      0.94        60\n",
      "          14       0.97      1.00      0.98        61\n",
      "          15       0.94      0.97      0.95        62\n",
      "          16       1.00      0.94      0.97        51\n",
      "\n",
      "    accuracy                           0.93      1071\n",
      "   macro avg       0.93      0.94      0.93      1071\n",
      "weighted avg       0.93      0.93      0.93      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[68  1  0  0  0  6  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 57  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 70  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 56  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  1  1 58  3  0  0  1  0  1  0  0  0  0  0  0]\n",
      " [ 8  2  1  0  0 37  1  0  1 11  0  1  1  7  0  4  0]\n",
      " [ 0  0  0  0  0  0 62  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0 68  0  0  0  0  0  0  2  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 57  0  0  0  0  0  0  0  0]\n",
      " [ 2  1  1  0  1  3  1  0  0 58  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 64  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  2  0  0  0  0  0 45  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0  0 67  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 60  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 61  0  0]\n",
      " [ 0  0  0  0  0  2  0  0  0  0  0  0  0  0  0 60  0]\n",
      " [ 0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0 48]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model - detailed evaluation\n",
    "print(\"\\n=== Random Forest Classifier Evaluation ===\")\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and scaler\n",
    "pickle.dump(scaler, open(\"scaler.pkl\", 'wb'))\n",
    "pickle.dump(rf_model, open(\"model.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendation system\n",
    "class_names = [\n",
    "    'Lawyer', 'Doctor', 'Government Officer', 'Artist', 'Unknown', 'Software Engineer',\n",
    "    'Teacher', 'Business Owner', 'Scientist', 'Banker', 'Writer', 'Accountant', 'Designer',\n",
    "    'Construction Engineer', 'Game Developer', 'Stock Investor', 'Real Estate Developer'\n",
    "]\n",
    "\n",
    "def Recommendations(gender, part_time_job, absence_days, extracurricular_activities,\n",
    "                    weekly_self_study_hours, math_score, history_score, physics_score,\n",
    "                    chemistry_score, biology_score, english_score, geography_score,\n",
    "                    total_score, average_score):\n",
    "    # Encode input\n",
    "    gender_encoded = 1 if gender.lower() == 'female' else 0\n",
    "    part_time_job_encoded = 1 if part_time_job else 0\n",
    "    extracurricular_activities_encoded = 1 if extracurricular_activities else 0\n",
    "\n",
    "    # Feature array\n",
    "    feature_array = np.array([[gender_encoded, part_time_job_encoded, absence_days,\n",
    "                               extracurricular_activities_encoded, weekly_self_study_hours,\n",
    "                               math_score, history_score, physics_score, chemistry_score,\n",
    "                               biology_score, english_score, geography_score, total_score, average_score]])\n",
    "\n",
    "    # Scale and predict\n",
    "    scaled_features = scaler.transform(feature_array)\n",
    "    probabilities = rf_model.predict_proba(scaled_features)\n",
    "\n",
    "    # Get top predictions\n",
    "    top_classes_idx = np.argsort(-probabilities[0])[:5]\n",
    "    return [(class_names[idx], probabilities[0][idx]) for idx in top_classes_idx]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
